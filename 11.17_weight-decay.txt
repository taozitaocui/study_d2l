ch4_weight_decay
理解：
过拟合可以通过增加训练集解决，但成本高，通常使用正则化技术解决。
权重衰减（weight_decay）是最广泛的正则化技术，被称为L2正则化，在优化器中提供。
L2范数惩罚最方便的方法是将所有参数w平方后求和并将结果加到目标函数（损失函数）中作为惩罚。(实际上用的是平方L2范数，减小运算量）
（参数w过大会导致过拟合，将参数w的L2范数添加到损失中，当w过大时，L2范数过大，导致损失过大，模型会更专注于减小参数w）
一般只考虑w的权重衰减，而不考虑b的
使用：
权重衰减在优化器中，L2范数惩罚作用在损失函数中。


损失函数与优化器的理解：对照图片理解
损失函数是目标，目标是让它趋近于0
如均方差损失函数，是n个模型预测值与真实值差的平方，再➗n，为了求导后美观✖1/2。当损失函数趋近于0，证明预测值与真实值几乎相同。
如SGD小批量随机梯度下降优化函数，用于更新权重w和偏置b，方法是将之前的参数减去batch_size个损失函数关于参数w或b的导数，再➗batch_size，再乘以学习率，
指的是让参数朝着目标函数下降最快的方向移动，这个方向就是梯度（上升最快）的反方向。